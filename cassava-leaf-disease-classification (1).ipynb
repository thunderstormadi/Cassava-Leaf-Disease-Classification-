{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13836,"databundleVersionId":1718836,"sourceType":"competition"}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport json\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2\nfrom PIL import Image\nimport hashlib\nimport os\nimport cv2","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"BASE_DIR = \"/kaggle/input/cassava-leaf-disease-classification\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"with open(\"/kaggle/input/cassava-leaf-disease-classification/label_num_to_disease_map.json\") as file:\n    print(\"yes\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 1: Load and inspect label map (mapping from numerical labels to disease names)\nwith open(os.path.join(BASE_DIR, \"label_num_to_disease_map.json\")) as file:\n    map_classes = json.loads(file.read())\n    map_classes = {int(k): v for k, v in map_classes.items()}\n\n# Display the mapping\nprint(\"Class Mapping: \")\nprint(json.dumps(map_classes, indent=4))\n\n# Check the contents of the train_images folder\nos.listdir(os.path.join(BASE_DIR, \"train_images\"))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 2: Load training image filenames and display the count\ninput_files = os.listdir(os.path.join(BASE_DIR, \"train_images\"))\nprint(f\"Number of train images: {len(input_files)}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 3: Load train.csv and add a human-readable class name based on the mapping\ndf_train = pd.read_csv(os.path.join(BASE_DIR, \"train.csv\"))\nprint(df_train.head())\n\n# Map the numerical label to the actual disease name\ndf_train[\"class_name\"] = df_train[\"label\"].map(map_classes)\n\n# Display the dataframe with the new column\ndf_train","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train['class_name'].value_counts()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 4: Check class distribution\nclass_distribution = df_train['class_name'].value_counts()\n\n# Plot the class distribution\nplt.figure(figsize=(10, 6))\nclass_distribution.plot(kind='bar')\nplt.title('Class Distribution of Cassava Leaf Disease')\nplt.ylabel('Number of Images')\nplt.xlabel('Disease Class')\nplt.xticks(rotation=45)\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Alternatively, use seaborn for a countplot visualization\nplt.figure(figsize=(8, 4))\nsns.countplot(y=\"class_name\", data=df_train)\nplt.title('Class Distribution (Seaborn)')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print('Dataset info :')\nprint(df_train.info())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print('\\nDataset summary statistics :')\nprint(df_train.describe())\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print('Missing values in each column :')\nprint(df_train.isnull().sum())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print('No of duplicated rows:')\nprint(df_train.duplicated().sum())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 7: Analyze image shapes (size dimensions) for a sample of 300 images\n# Dictionary to store image shapes and their counts\nimg_shapes = {}\nfor image_name in os.listdir(os.path.join(BASE_DIR, \"train_images\"))[:500]:\n    image = cv2.imread(os.path.join(BASE_DIR, \"train_images\", image_name))\n    img_shapes[image.shape] = img_shapes.get(image.shape, 0) + 1\n\n# Display image shapes\nprint(\"\\nSample Image Shapes and their Frequencies (from 1000 images):\")\nprint(img_shapes)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport os\nfrom PIL import Image\n\n# Step 8: Function to plot sample images from a specific class\ndef plot_images_from_class(class_id, num_images=9):\n    \"\"\"\n    Plot sample images from a specific class in a 3x3 grid.\n    \n    Parameters:\n        class_id (int): The class label to filter images.\n        num_images (int): The number of images to plot.\n    \"\"\"\n    # Filter images for the specified class\n    class_images = df_train[df_train['label'] == class_id]\n    num_images = min(len(class_images), num_images) # Adjust if fewer images than\n    \n    plt.figure(figsize=(15, 15)) # Set figure size for better visualization\n    images = class_images.sample(num_images) # Randomly sample images\n    \n    # Plot images in a 3x3 grid\n    for i, (_, row) in enumerate(images.iterrows()):\n        img_path = os.path.join(BASE_DIR, \"train_images\", row['image_id'])\n        img = Image.open(img_path)\n        plt.subplot(3, 3, i + 1)\n        plt.imshow(img)\n        plt.title(map_classes[class_id]) # Use class name for the title\n        plt.axis('off') # Hide axis for better visualization\n        \n    plt.tight_layout() # Adjust layout to prevent overlap\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_images_from_class(0)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for i in range(5):\n    print(f\"Displaying sample images for class: {map_classes[i]}\")\n    plot_images_from_class(i)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train['image_shape'] = df_train['image_id'].apply(lambda x: cv2.imread(os.path.join(BASE_DIR,\"train_images\",x)).shape)\nshape_class_dist = df_train.groupby(['class_name','image_shape']).size().unstack(fill_value=0)\nshape_class_dist.T.plot(kind='bar', stacked=True, figsize=(12, 6))\nplt.title('Image Size Distribution by Class')\nplt.xlabel('Image Shape')\nplt.ylabel('Number of Images')\nplt.legend(title='Class Name', bbox_to_anchor=(1.05, 1), loc='upper left')\nplt.xticks(rotation=45)\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train['label_names'] = df_train['label'].map(map_classes)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_image_hash(image_path):\n    \"\"\"Generate an MD5 hash for the image.\"\"\"\n    with open(image_path, \"rb\") as f:\n        file_hash = hashlib.md5(f.read()).hexdigest()\n    return file_hash\n\n# Dictionary to store image hashes and their file names\nimage_hashes = {}\n\n# Check for duplicate images\nduplicate_images = []\n\n# Note: BASE_DIR must be defined before running this loop\nfor image_name in os.listdir(os.path.join(BASE_DIR, \"train_images\")):\n    image_path = os.path.join(BASE_DIR, \"train_images\", image_name)\n    image_hash = get_image_hash(image_path)\n    \n    if image_hash in image_hashes:\n        # If hash exists, it's a duplicate. Append the current name and the original name.\n        duplicate_images.append((image_name, image_hashes[image_hash]))\n    else:\n        image_hashes[image_hash] = image_name  # Store the hash\n\nprint(f\"Found {len(duplicate_images)} exact duplicate images.\")\nfor dup in duplicate_images:\n    print(f\"Duplicate pair: {dup[0]} and {dup[1]}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(image_hashes)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import models, layers\n\nmodel = models.Sequential()\n\n# 1st Convolutional block\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.MaxPooling2D((2, 2)))\n\n# 2nd Convolutional block\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.MaxPooling2D((2, 2)))\n\n# 3rd Convolutional block\nmodel.add(layers.Conv2D(128, (3, 3), activation='relu'))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.MaxPooling2D((2, 2)))\n\n# 4th Convolutional block\nmodel.add(layers.Conv2D(256, (3, 3), activation='relu'))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.MaxPooling2D((2, 2)))\n\n# Flatten the output to feed it into fully connected layers\nmodel.add(layers.Flatten())\n\n# Dense layer with 512 units\nmodel.add(layers.Dense(512, activation='relu'))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.Dropout(0.5))\n\n# Output layer for classification (assuming 5 classes)\nmodel.add(layers.Dense(5, activation='softmax'))\n\n# Compile the model\nmodel.compile(optimizer='adam',\n              loss='categorical_crossentropy', # Assuming sparse labels (integers)\n              metrics=['accuracy'])\n\n# Model summary\nmodel.summary()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Depracated techniques","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"images_dir = '/kaggle/input/cassava-leaf-disease-classification/train_images'","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n# 2. Create an ImageDataGenerator to preprocess images\n# normalizing pixel values (1./255) and setting a validation split of 20%\ndatagen = ImageDataGenerator(rescale=1./255,\n                             validation_split=0.2)\n\n# 3. Generate Training Dataset\ntrain_dataset = datagen.flow_from_dataframe(\n    dataframe=df_train,\n    directory=images_dir,\n    x_col=\"image_id\",       # Column containing file names\n    y_col=\"class_name\",     # Column containing labels (must match map_classes values)\n    target_size=(224, 224), # Resize images to match model input\n    batch_size=32,\n    class_mode=\"categorical\",\n    subset=\"training\",\n    shuffle=True\n)\n\n# 4. Generate Validation Dataset\nval_dataset = datagen.flow_from_dataframe(\n    dataframe=df_train,\n    directory=images_dir,\n    x_col=\"image_id\",\n    y_col=\"class_name\",\n    target_size=(224, 224),\n    batch_size=32,\n    class_mode=\"categorical\",\n    subset=\"validation\",\n    shuffle=True\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 5. Train the model for 10 epochs\nhistory = model.fit(\n    train_dataset,\n    validation_data=val_dataset,\n    epochs=10\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Using tensorflow dataset","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Option 1: Using pandas' vectorized string operations\n# This prepends the directory path to the filename in the 'image_id' column\ndf_train['image_id'] = \"/kaggle/input/cassava-leaf-disease-classification/train_images/\" + df_train['image_id']\n\n# Display the first few rows to verify the updated paths\ndf_train.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Define the validation split ratio\nVALIDATION_SPLIT = 0.2  # 20% for validation\n\n# Perform stratified split to maintain class distribution\n# This ensures that both train and validation sets have the same percentage of each disease class\ntrain_df, val_df = train_test_split(\n    df_train,\n    test_size=VALIDATION_SPLIT,\n    stratify=df_train['label'],\n    random_state=42\n)\n\nprint(f\"Training samples: {len(train_df)}\")\nprint(f\"Validation samples: {len(val_df)}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Training class distribution:\")\nprint(train_df['label'].value_counts())\n\nprint(\"\\nValidation class distribution:\")\nprint(val_df['label'].value_counts())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 1. Configuration Constants\nIMG_HEIGHT = 224\nIMG_WIDTH = 224\nCHANNELS = 3\nBATCH_SIZE = 32\nBUFFER_SIZE = 1000\nAUTOTUNE = tf.data.AUTOTUNE","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 2. Define the Image Processing Function\ndef process_image(file_path, label):\n    \"\"\"\n    Reads an image from a file path, decodes it, resizes it, and normalizes it.\n    \"\"\"\n    # Read the image from disk\n    image = tf.io.read_file(file_path)\n    \n    # Decode the image (assuming JPEG format)\n    image = tf.image.decode_jpeg(image, channels=CHANNELS)\n    \n    # Resize the image\n    image = tf.image.resize(image, [IMG_HEIGHT, IMG_WIDTH])\n    \n    # Normalize pixel values to [0, 1]\n    image = image / 255.0\n    \n    return image, label\n\n# 3. Create Training Dataset","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 3. Create TensorFlow Dataset from training DataFrame\n# Note: Assumes 'train_df' is already defined and has 'image_id' (full paths) and 'label' columns\ntrain_ds = tf.data.Dataset.from_tensor_slices((train_df['image_id'].values, train_df['label'].values))\n\n# Map the processing function to each (image, label) pair\ntrain_ds = train_ds.map(process_image, num_parallel_calls=AUTOTUNE)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Data Augmentation (optional but recommended)\ndata_augmentation = tf.keras.Sequential([\n    layers.RandomFlip('horizontal'),\n    layers.RandomRotation(0.1),\n    layers.RandomZoom(0.1),\n    layers.RandomContrast(0.1),\n])\n\ndef augment(image, label):\n    \"\"\"Applies data augmentation to the image.\"\"\"\n    image = data_augmentation(image)\n    return image, label\n\n# Apply augmentation to the training dataset\n# Note: 'train_ds' must be defined from the previous step before running this\ntrain_ds = train_ds.map(augment, num_parallel_calls=AUTOTUNE)\n\n# Shuffle, batch, and prefetch the dataset for optimal performance\n# Note: 'BUFFER_SIZE', 'BATCH_SIZE', and 'AUTOTUNE' should be defined previously\ntrain_ds = train_ds.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(AUTOTUNE)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create TensorFlow Dataset from validation DataFrame\n# Note: Assumes 'val_df' is already defined from the train_test_split step\nval_ds = tf.data.Dataset.from_tensor_slices((val_df['image_id'].values, val_df['label'].values))\n\n# Map the processing function\n# Note: 'process_image' function and 'AUTOTUNE' must be defined previously\nval_ds = val_ds.map(process_image, num_parallel_calls=AUTOTUNE)\n\n# Batch and prefetch\n# We do NOT shuffle the validation data\nval_ds = val_ds.batch(BATCH_SIZE).prefetch(AUTOTUNE)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras import regularizers\n\nnum_classes = 5\n\n# Define the CNN model architecture\ndef create_cnn_model(input_shape=(IMG_HEIGHT, IMG_WIDTH, CHANNELS), num_classes=5):\n    model = models.Sequential([\n        # 1st Convolutional block\n        layers.Input(shape=input_shape),\n        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n        layers.BatchNormalization(),\n        layers.MaxPooling2D((2, 2)),\n\n        # 2nd Convolutional block\n        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n        layers.BatchNormalization(),\n        layers.MaxPooling2D((2, 2)),\n\n        # 3rd Convolutional block\n        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n        layers.BatchNormalization(),\n        layers.MaxPooling2D((2, 2)),\n\n        # 4th Convolutional block\n        layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n        layers.BatchNormalization(),\n        layers.MaxPooling2D((2, 2)),\n\n        # Flatten and Dense layers\n        layers.Flatten(),\n        layers.Dense(512, activation='relu'),\n        layers.BatchNormalization(),\n        layers.Dropout(0.5),\n\n        # Output layer\n        layers.Dense(num_classes, activation='softmax')\n    ])\n    \n    return model\n\n# Instantiate the model\n# Note: IMG_HEIGHT, IMG_WIDTH, CHANNELS must be defined from previous steps\nmodel = create_cnn_model(input_shape=(IMG_HEIGHT, IMG_WIDTH, CHANNELS), num_classes=num_classes)\n\n# Display the model architecture\nmodel.summary()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Compile the model\nmodel.compile(\n    optimizer='adam',  # You can experiment with different optimizers\n    loss='sparse_categorical_crossentropy',  # Suitable for integer-encoded labels\n    metrics=['accuracy']\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n\n# Early stopping to prevent overfitting\nearly_stop = EarlyStopping(\n    monitor='val_loss',\n    patience=3,\n    restore_best_weights=True,\n    verbose=1\n)\n\n# Model checkpoint to save the best model\ncheckpoint = ModelCheckpoint(\n    'best_cnn_model.keras',\n    monitor='val_accuracy',\n    save_best_only=True,\n    verbose=1\n)\n\n# Reduce learning rate when a metric has stopped improving\nreduce_lr = ReduceLROnPlateau(\n    monitor='val_loss',\n    factor=0.2,\n    patience=3,\n    verbose=1,\n    min_lr=1e-6\n)\n\ncallbacks = [early_stop , checkpoint , reduce_lr]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define the number of epochs\nEPOCHS = 10  # Adjust based on your requirements\n\n# Group the individual callbacks from the previous step into a list\ncallbacks = [early_stop, checkpoint, reduce_lr]\n\n# Train the model\nhistory = model.fit(\n    train_ds,\n    validation_data=val_ds,\n    epochs=EPOCHS,\n    callbacks=callbacks\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 14: Evaluate the Model\nval_loss, val_accuracy = model.evaluate(val_ds)\nprint(f\"\\nValidation Loss: {val_loss:.4f}\")\nprint(f\"Validation Accuracy: {val_accuracy:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Retrieve metrics from history\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs_range = range(len(acc))\n\n# Plot Accuracy\nplt.figure(figsize=(14, 6))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\n# Plot Loss\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}